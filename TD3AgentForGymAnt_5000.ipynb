{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3eaec728",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This implementation is based on the guidance from the SpinningUp article:\n",
    "https://spinningup.openai.com/en/latest/algorithms/td3.html\n",
    "\"\"\"\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "## ----------------- Helpers ---------------- ## \n",
    "\n",
    "def flatten(nestedTuple: tuple):\n",
    "    \"\"\"\n",
    "    flatten input dimensions for NNs\n",
    "    \"\"\"\n",
    "    merged = []\n",
    "    for item in nestedTuple:\n",
    "        if isinstance(item, tuple) or isinstance(item, list):\n",
    "            for i in item:\n",
    "                merged.append(i)\n",
    "        else:\n",
    "            merged.append(item)  \n",
    "    return merged   \n",
    "\n",
    "## This function aims to help updating target actor/critic parameters\n",
    "def targetUpdater(normalModel, targetModel, lRate = 0.3):\n",
    "    for normalParam, targetParam in zip(normalModel.parameters(), targetModel.parameters()):\n",
    "        targetParam.data.copy_(targetParam.data * (1.0 - lRate) + normalParam.data * lRate)\n",
    "## This function aims to initilize target actor/critic parameters with normal Actor/Critc \n",
    "def initializer(normalModel, targetModel):\n",
    "    for normalParam, targetParam in zip(normalModel.parameters(), targetModel.parameters()):\n",
    "        targetParam.data.copy_(normalParam.data)\n",
    "    \n",
    "## ------------------ Actor ----------------- ## \n",
    "\n",
    "class Actor(nn.Module):\n",
    "    \"\"\"\n",
    "    hidden layer can be further defined using another tuple e.g. (30, (128,64), 8) \n",
    "    or simply define in one tuple (30, 128, 64, 8)\n",
    "    \"\"\"\n",
    "    def __init__(self, structure, use_dropout = False):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        layers = []\n",
    "        ## Activation function:\n",
    "        self.activation  = nn.ReLU()\n",
    "        \n",
    "        # Automatic population of FC network\n",
    "        dim = flatten(structure)\n",
    "        dim_shifted = dim[1:]\n",
    "        \n",
    "        for i in range(len(dim)-1):\n",
    "            layers.append(nn.Linear(dim[i], dim_shifted[i]))\n",
    "            \n",
    "            ## Just in case for mitigating overfitting ...\n",
    "            if use_dropout and i != len(dim)-2:\n",
    "                layers.append(nn.Dropout(p = 0.2))\n",
    "            \n",
    "            if i != len(dim)-2:\n",
    "                layers.append(self.activation)\n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, states):\n",
    "        output = self.model(states)\n",
    "        ## This is to scale back the actions to (-1, 1) for Ant environment !Need to change for other environmen\n",
    "        output = torch.tanh(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "## -------------------Critic ---------------- ## \n",
    "class Critic(nn.Module):\n",
    "    \"\"\"\n",
    "    Critic network input dimension must equal the states_dim + actions_dim\n",
    "    \"\"\"\n",
    "    def __init__(self, structure, use_dropout = False):\n",
    "        super().__init__()\n",
    "        \n",
    "        layers = []\n",
    "        ## Activation function:\n",
    "        self.activation  = nn.ReLU()\n",
    "        \n",
    "        # Automatic population of FC network\n",
    "        dim = flatten(structure)\n",
    "        dim_shifted = dim[1:]\n",
    "        \n",
    "        for i in range(len(dim)-1):\n",
    "            layers.append(nn.Linear(dim[i], dim_shifted[i]))\n",
    "            \n",
    "            ## Just in case for mitigating overfitting ...\n",
    "            if use_dropout and i != len(dim)-2:\n",
    "                layers.append(nn.Dropout(p = 0.2))\n",
    "                \n",
    "            if i != len(dim)-2:\n",
    "                layers.append(self.activation)\n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, states, actions):\n",
    "        \n",
    "        ## concatenate states and actions, order shouldn't really matter\n",
    "        inputs = torch.cat([states, actions], 1)\n",
    "        output = self.model(inputs)\n",
    "        return output\n",
    "\n",
    "\n",
    "## -------------------Replay ---------------- ## \n",
    "class ReplayMemory():\n",
    "    \n",
    "    def __init__(self, size=500):\n",
    "        self.size = size\n",
    "        self.memory = []\n",
    "        \n",
    "    def addMemory(self, transition):\n",
    "        \"\"\"\n",
    "        Transition composition:\n",
    "        State, Action, Reward, `State\n",
    "        \"\"\"\n",
    "        if self.isFull():\n",
    "            ## If memory is full, remove the first stored elements\n",
    "            self.memory.pop(0)\n",
    "            \n",
    "        self.memory.append(transition)\n",
    "                \n",
    "    def sample(self, batchSize):\n",
    "        ## This is a very slow implementation - should be optimized if possible\n",
    "        batch = random.sample(self.memory, batchSize)\n",
    "        state, action, reward, stateNext, terminated = [], [], [], [], []\n",
    "        for transition in batch:\n",
    "            state.append(transition[0])\n",
    "            action.append(transition[1])\n",
    "            reward.append(transition[2])\n",
    "            stateNext.append(transition[3])\n",
    "            terminated.append(transition[4])\n",
    "        \n",
    "        return state, action, reward, stateNext, terminated\n",
    "    \n",
    "    def isFull(self):\n",
    "        return len(self.memory)==self.size\n",
    "    \n",
    "    def getSize(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "\n",
    "## ------------------- Target policy smoothing ---------------- ## \n",
    "class policySmooth:\n",
    "    def __init__(self,  actionSpace, std = 0.2, clip = 0.3,):\n",
    "        \n",
    "        self.std = std\n",
    "        self.clip = clip\n",
    "        self.size = actionSpace.shape[0]\n",
    "        self.high = actionSpace.high\n",
    "        self.low = actionSpace.low\n",
    "        \n",
    "    def getAction(self, actionIn, noiseClip = True):\n",
    "        noise = np.random.normal(0, self.std, self.size)\n",
    "        \n",
    "        ## For action no clipping, for target action apply clip\n",
    "        if noiseClip:\n",
    "            noise = np.clip(noise, -self.clip, self.clip)\n",
    "        action = actionIn + noise\n",
    "        \n",
    "        return np.clip(action, self.low, self.high)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52fb0c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "class TD3Agent:\n",
    "    \n",
    "    def __init__(self, actionSpace, actorStructure:tuple, criticStructure:tuple, use_dropout = False, actorLRate = 0.0003, criticLRate = 0.0003, criticLoss = 'HL', gamma = 0.9, targetUpdaterLRate = 0.3, replayMemorySize = 500, batchSize = 128, policyDelay = 2, gpu = True):\n",
    "        \n",
    "        self.actor = Actor(structure=actorStructure, use_dropout = use_dropout)\n",
    "        self.critic1 = Critic(structure=criticStructure, use_dropout = use_dropout)\n",
    "        self.critic2 = Critic(structure=criticStructure, use_dropout = use_dropout)\n",
    "        \n",
    "        self.targetActor = Actor(structure=actorStructure, use_dropout = use_dropout)\n",
    "        self.targetCritic1 = Critic(structure=criticStructure, use_dropout = use_dropout)\n",
    "        self.targetCritic2 = Critic(structure=criticStructure, use_dropout = use_dropout)\n",
    "        \n",
    "        self.batchSize = batchSize\n",
    "        self.targetUpdaterLRate = targetUpdaterLRate\n",
    "        self.gamma = gamma\n",
    "        self.gpu = gpu\n",
    "        self.policyDelay = policyDelay\n",
    "        if self.gpu:\n",
    "            self.cuda()\n",
    "        \n",
    "        ## initialise target models \n",
    "        initializer(self.actor, self.targetActor)\n",
    "        initializer(self.critic1, self.targetCritic1)\n",
    "        initializer(self.critic2, self.targetCritic2)\n",
    "        \n",
    "        ## initialise replay memory and random process\n",
    "        self.pSmooth = policySmooth(actionSpace)\n",
    "        self.rMemory = ReplayMemory(replayMemorySize)\n",
    " \n",
    "        \n",
    "        ## initialise optimizer\n",
    "        self.actorOptim = optim.Adam(self.actor.parameters(), lr=actorLRate)\n",
    "        self.criticOptim1 = optim.Adam(self.critic1.parameters(), lr=criticLRate)\n",
    "        self.criticOptim2 = optim.Adam(self.critic2.parameters(), lr=criticLRate)\n",
    "        \n",
    "        ## initialise Loss for critic, either Huber (default) or MSE (otherwise)\n",
    "        if criticLoss == 'HL':\n",
    "            self.criticCriteria1 = nn.HuberLoss()\n",
    "            self.criticCriteria2 = nn.HuberLoss()\n",
    "        \n",
    "        else:\n",
    "            self.criticCriteria1 = nn.MSELoss()\n",
    "            self.criticCriteria2 = nn.MSELoss()\n",
    "    def updatePolicy(self, num):\n",
    "        ## Assuming sufficient replay memory has been acquired\n",
    "        \n",
    "        ## 1. Sample (S, A, R, S`) in replay memory\n",
    "        if self.rMemory.isFull():\n",
    "            state, action, reward, stateNext, terminated = self.rMemory.sample(self.batchSize)\n",
    "        \n",
    "            if self.gpu:\n",
    "                state = torch.cuda.FloatTensor(state)\n",
    "                action = torch.cuda.FloatTensor(action)\n",
    "                reward = torch.cuda.FloatTensor(reward)\n",
    "                stateNext = torch.cuda.FloatTensor(stateNext)\n",
    "                terminated = torch.cuda.FloatTensor(terminated)\n",
    "                \n",
    "            else:\n",
    "                state = torch.FloatTensor(state)\n",
    "                action = torch.FloatTensor(action)\n",
    "                reward = torch.FloatTensor(reward)\n",
    "                stateNext = torch.FloatTensor(stateNext)\n",
    "                terminated = torch.FloatTensor(terminated)\n",
    "\n",
    "            ## 2. Gradient of actor and critic  \n",
    "            \n",
    "            targetAction = self.pSmooth.getAction(self.targetActor(stateNext).detach().cpu().numpy(), noiseClip=True)\n",
    "            if self.gpu:\n",
    "                targetAction = torch.cuda.FloatTensor(targetAction)\n",
    "            else:\n",
    "                targetAction = torch.FloatTensor(targetAction)\n",
    "            Q1 = self.targetCritic1(stateNext.detach(), targetAction.detach())\n",
    "            Q2 = self.targetCritic2(stateNext.detach(), targetAction.detach())\n",
    "            \n",
    "            ## SMALLER Q Proceed (this verion consider actions individually)\n",
    "            if Q1.mean() > Q2.mean():\n",
    "                Q = Q2\n",
    "            else:\n",
    "                Q = Q1\n",
    "             \n",
    "            y = self.gamma * (1 - terminated) * Q + reward\n",
    "            y.requires_grad_()\n",
    "            \n",
    "      \n",
    "            yBar1 = self.critic1(state, action)\n",
    "            yBar2 = self.critic2(state, action)\n",
    "  \n",
    "            criticLoss1 = self.criticCriteria1(yBar1, y)\n",
    "            criticLoss2 = self.criticCriteria2(yBar2, y)\n",
    "            \n",
    "            ## backward losses\n",
    "            self.criticOptim1.zero_grad()\n",
    "            criticLoss1.backward(retain_graph = True)\n",
    "            self.criticOptim1.step()\n",
    "            \n",
    "            self.criticOptim2.zero_grad()\n",
    "            criticLoss2.backward()\n",
    "            self.criticOptim2.step()\n",
    "            \n",
    "            ## update actor when delay condition is met\n",
    "            if num % self.policyDelay == 0:\n",
    "                actorLoss = -self.critic1(state, self.actor(state)).mean()\n",
    "                self.actorOptim.zero_grad()\n",
    "                actorLoss.backward()\n",
    "                self.actorOptim.step()\n",
    "            ## 3. Update target actor / critic\n",
    "                targetUpdater(self.critic1, self.targetCritic1, self.targetUpdaterLRate)\n",
    "                targetUpdater(self.critic2, self.targetCritic2, self.targetUpdaterLRate)\n",
    "                targetUpdater(self.actor, self.targetActor, self.targetUpdaterLRate)\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(\"More replay memory needed\")\n",
    "    \n",
    "    ## Add option to discard noise in eval mode\n",
    "    def getAction(self, states, eval = False):\n",
    "        if self.gpu:\n",
    "            states = torch.cuda.FloatTensor(states)\n",
    "        else:\n",
    "            states = torch.FloatTensor(states)\n",
    "        \n",
    "        action = self.actor(states).detach().cpu().numpy()\n",
    "        \n",
    "        # Action selection without noise clip\n",
    "        if not eval:\n",
    "            action = self.pSmooth.getAction(action, noiseClip=False)\n",
    "            \n",
    "        return action\n",
    "    \n",
    "    def cuda(self):\n",
    "        ## Move all models to GPU\n",
    "        if torch.cuda.is_available():\n",
    "            self.actor.cuda()\n",
    "            self.critic1.cuda()\n",
    "            self.critic2.cuda()\n",
    "            self.targetActor.cuda()\n",
    "            self.targetCritic1.cuda()\n",
    "            self.targetCritic2.cuda()\n",
    "        else:\n",
    "            raise ValueError(\"No Cuda Available\")\n",
    "            \n",
    "    def cpu(self):\n",
    "        ## Move all models back to CPU\n",
    "        self.actor.cpu()\n",
    "        self.critic1.cpu()\n",
    "        self.critic2.cpu()\n",
    "        self.targetActor.cpu()\n",
    "        self.targetCritic1.cpu()\n",
    "        self.targetCritic2.cpu()\n",
    "        \n",
    "    def evalMode(self):\n",
    "        ## Evaluation mode for Agent showcase \n",
    "        self.actor.eval()\n",
    "        self.critic1.eval()\n",
    "        self.critic2.eval()\n",
    "        self.targetActor.eval()\n",
    "        self.targetCritic1.eval()  \n",
    "        self.targetCritic2.eval() \n",
    "        \n",
    "    def trainMode(self):\n",
    "        ## Training mode for updating parameters\n",
    "        self.actor.train()\n",
    "        self.critic1.train()\n",
    "        self.critic2.train()\n",
    "        self.targetActor.train()\n",
    "        self.targetCritic1.train() \n",
    "        self.targetCritic2.train() \n",
    "        \n",
    "    def saveModel(self, path):\n",
    "        torch.save(self.actor.state_dict(),f'{path}/actor.pkl')\n",
    "        torch.save(self.targetActor.state_dict(),f'{path}/targetActor.pkl')\n",
    "        \n",
    "        torch.save(self.critic1.state_dict(),f'{path}/critic1.pkl')\n",
    "        torch.save(self.critic2.state_dict(),f'{path}/critic2.pkl')\n",
    "        \n",
    "        torch.save(self.targetCritic1.state_dict(),f'{path}/targetCritic1.pkl')\n",
    "        torch.save(self.targetCritic2.state_dict(),f'{path}/targetCritic2.pkl')    \n",
    "        \n",
    "    def loadModel(self, path):\n",
    "        self.actor.load_state_dict(torch.load(f'{path}/actor.pkl'))\n",
    "        self.targetActor.load_state_dict(torch.load(f'{path}/targetActor.pkl'))\n",
    "        \n",
    "        self.critic1.load_state_dict(torch.load(f'{path}/critic1.pkl'))\n",
    "        self.critic2.load_state_dict(torch.load(f'{path}/critic2.pkl'))\n",
    "        \n",
    "        self.targetCritic1.load_state_dict(torch.load(f'{path}/targetCritic1.pkl'))\n",
    "        self.targetCritic2.load_state_dict(torch.load(f'{path}/targetCritic2.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ba29cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(agent, env, epochs, replayMemorySize, updateStart, printEvery = 100, savePath=None):\n",
    "\n",
    "    # ## Training Loop\n",
    "    try:\n",
    "        for e in range(epochs):\n",
    "            state = env.reset()    \n",
    "            episodeR = 0\n",
    "            t = 0\n",
    "            # Training loop for each episode\n",
    "            while True:\n",
    "                \n",
    "                # Fill in the replay memory\n",
    "                action = agent.getAction(state)\n",
    "                stateNext, reward, terminated, truncated, info = env.step(action)\n",
    "                agent.rMemory.addMemory((state, action, np.array([reward]), stateNext, np.array([terminated])))\n",
    "\n",
    "                ## Update policy when memory is ready\n",
    "                if agent.rMemory.getSize() > updateStart: \n",
    "                    agent.updatePolicy(t)\n",
    "                    t+=1\n",
    "\n",
    "                ## renew state and action\n",
    "                state = stateNext\n",
    "                episodeR += reward\n",
    "       \n",
    "                if terminated or truncated:\n",
    "                    break\n",
    "                \n",
    "            rewardTracking.append(episodeR)\n",
    "            rewardAvg.append(np.mean(rewardTracking[-10:]))\n",
    "            \n",
    "            if (e+1)%printEvery == 0:\n",
    "                print(f\"Episode {e+1}: reward: {episodeR}, Avg: {rewardAvg[-1]}\")\n",
    "        \n",
    "        ## Only save model if reward increased\n",
    "        if savePath!=None and (rewardTracking[-1] > rewardTracking[-2]):\n",
    "            \n",
    "            agent.saveModel(savePath)\n",
    "    \n",
    "    ## In case looping for too long\n",
    "    except KeyboardInterrupt:\n",
    "        return rewardTracking, rewardAvg \n",
    "    \n",
    "    return rewardTracking, rewardAvg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1137ec4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linghao/env/p37_r/lib/python3.7/site-packages/ipykernel_launcher.py:54: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:204.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100: reward: 144.15827405753475, Avg: 464.63530990711126\n",
      "Episode 200: reward: 93.8453779109219, Avg: 289.02831655414946\n",
      "Episode 300: reward: 317.8178190085461, Avg: 516.744482515704\n",
      "Episode 400: reward: 267.61715176967755, Avg: 236.37530109783248\n",
      "Episode 500: reward: 558.9646942739416, Avg: 489.51974334475307\n",
      "Episode 600: reward: 884.4777181835298, Avg: 427.9222338827256\n",
      "Episode 700: reward: 91.62446638117214, Avg: 590.8158777152775\n",
      "Episode 800: reward: 2046.4650420580354, Avg: 964.1300169767953\n",
      "Episode 900: reward: 511.3044827194967, Avg: 357.783547005498\n",
      "Episode 1000: reward: 263.78332995277395, Avg: 393.85040293978113\n",
      "Episode 1100: reward: 901.3575682645275, Avg: 622.2589699622469\n",
      "Episode 1200: reward: 705.9699946745766, Avg: 952.3659221642038\n",
      "Episode 1300: reward: 113.34575049464213, Avg: 1035.0167392637904\n",
      "Episode 1400: reward: 92.07399819869131, Avg: 358.5177814666973\n",
      "Episode 1500: reward: 267.349809451962, Avg: 510.398151576365\n",
      "Episode 1600: reward: 240.1126103192309, Avg: 499.2770695789848\n",
      "Episode 1700: reward: 61.27051691411704, Avg: 527.5928391480463\n",
      "Episode 1800: reward: 82.2515280692176, Avg: 391.52245791214744\n",
      "Episode 1900: reward: 487.76627819649156, Avg: 429.876103544747\n",
      "Episode 2000: reward: 553.3141549225772, Avg: 420.4646299758709\n",
      "Episode 2100: reward: 1283.0273608582715, Avg: 532.919426384357\n",
      "Episode 2200: reward: 236.73021173437388, Avg: 348.1677151743787\n",
      "Episode 2300: reward: 35.41818062988054, Avg: 577.7240776928804\n",
      "Episode 2400: reward: 43.2882924247254, Avg: 515.6263448071483\n",
      "Episode 2500: reward: 1241.8695436224502, Avg: 624.3563679193863\n",
      "Episode 2600: reward: 42.142250207703, Avg: 249.91720015618648\n",
      "Episode 2700: reward: 702.3599898567277, Avg: 463.5927305581341\n",
      "Episode 2800: reward: 592.5213263955385, Avg: 342.31272433236836\n",
      "Episode 2900: reward: 27.965388071750105, Avg: 258.98221233623303\n",
      "Episode 3000: reward: 904.5064931775789, Avg: 347.44284013006273\n",
      "Episode 3100: reward: 945.5416898400988, Avg: 365.27271804360606\n",
      "Episode 3200: reward: 183.53728580942894, Avg: 397.92733853557996\n",
      "Episode 3300: reward: 325.5914342849156, Avg: 758.5093620327517\n",
      "Episode 3400: reward: 1711.6115097123356, Avg: 636.1493620883482\n",
      "Episode 3500: reward: 373.5817540392395, Avg: 401.81586817828645\n",
      "Episode 3600: reward: 320.38876979750927, Avg: 386.78313814365\n",
      "Episode 3700: reward: 81.24115143003165, Avg: 622.1465813892971\n",
      "Episode 3800: reward: 15.187080100097461, Avg: 475.70663305251526\n",
      "Episode 3900: reward: 753.5881603264938, Avg: 455.7729416146377\n",
      "Episode 4000: reward: 26.252821130808126, Avg: 416.709608754302\n",
      "Episode 4100: reward: 822.6692075255716, Avg: 232.87050067399272\n",
      "Episode 4200: reward: 953.6673773986538, Avg: 618.5848803114268\n",
      "Episode 4300: reward: 38.88461525982549, Avg: 347.37136713695224\n",
      "Episode 4400: reward: 261.16245784148936, Avg: 658.1414824165854\n",
      "Episode 4500: reward: 20.46522891944558, Avg: 449.8857532956583\n",
      "Episode 4600: reward: 1470.096235234963, Avg: 637.6480250509636\n",
      "Episode 4700: reward: 244.1462480705794, Avg: 921.5323800355493\n",
      "Episode 4800: reward: 650.4790232224368, Avg: 745.9249318911576\n",
      "Episode 4900: reward: 84.11014723394867, Avg: 446.21155053401935\n",
      "Episode 5000: reward: 856.3122056409069, Avg: 591.8163178923918\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script is used as main for learning\n",
    "\"\"\"\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "## reset environment, render is not used in training\n",
    "env = gym.make('Ant-v4', new_step_api = True)\n",
    "env.action_space.seed(42)\n",
    "state = env.reset()\n",
    "\n",
    "## Observation and action space size\n",
    "observationNum = env.observation_space.shape[0]\n",
    "actionNum = env.action_space.shape[0]\n",
    "totalNum = observationNum + actionNum\n",
    "\n",
    "## Training Parameters\n",
    "epochs = 5000\n",
    "batchSize = 128\n",
    "gpu = True\n",
    "rewardTracking = []\n",
    "rewardAvg = []\n",
    "replayMemorySize = 10000\n",
    "printE = 100\n",
    "path = '/home/linghao/Desktop/'\n",
    "## Initialise TD3 agent\n",
    "\n",
    "## Some implementation suggest a single output from critic - can try\n",
    "agent = TD3Agent(env.action_space,\n",
    "                (observationNum, 256, 128, actionNum), \n",
    "                (totalNum, 256, 128, actionNum), \n",
    "                actorLRate = 0.0001, criticLRate = 0.0001, criticLoss = 'HL', gamma = 0.95, targetUpdaterLRate = 0.05,\n",
    "                replayMemorySize = replayMemorySize, gpu=gpu, batchSize=batchSize)\n",
    "agent.trainMode()\n",
    "trackR, avgR = train(agent, env, epochs=epochs, replayMemorySize = replayMemorySize, updateStart = 1000, printEvery=printE, savePath=path)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88b38310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fdf2f1e8490>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(avgR)\n",
    "# plt.plot(trackR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebd5ce4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "# from gym.wrappers.monitoring.video_recorder import VideoRecorder\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "newEnv =  gym.make('Ant-v4', render_mode = 'human', new_step_api = True)\n",
    "observation = newEnv.reset()\n",
    "\n",
    "## Observation and action space size\n",
    "observationNum = 27\n",
    "actionNum = 8\n",
    "totalNum = observationNum + actionNum\n",
    "\n",
    "## Training Parameters\n",
    "epochs = 5000\n",
    "batchSize = 128\n",
    "gpu = True\n",
    "rewardTracking = []\n",
    "rewardAvg = []\n",
    "replayMemorySize = 10000\n",
    "printE = 100\n",
    "path = '/home/linghao/Desktop/'\n",
    "\n",
    "agentEval = TD3Agent(newEnv.action_space,\n",
    "                (observationNum, 256, 128, actionNum), \n",
    "                (totalNum, 256, 128, actionNum), \n",
    "                actorLRate = 0.0001, criticLRate = 0.0001, criticLoss = 'HL', gamma = 0.95, targetUpdaterLRate = 0.05,\n",
    "                replayMemorySize = replayMemorySize, gpu=gpu, batchSize=batchSize)\n",
    "agentEval.loadModel('/home/linghao/Desktop/TD3/')\n",
    "agentEval.evalMode()\n",
    "\n",
    "\n",
    " \n",
    "# video_recorder = VideoRecorder(newEnv, '/home/linghao/Desktop/Ant.mp4', enabled=True)\n",
    "\n",
    "R = 0\n",
    "\n",
    "for _ in range(1000):\n",
    "#     video_recorder.capture_frame()\n",
    "    observation, reward, terminated, truncated, info = newEnv.step(agentEval.getAction(observation, eval = True))\n",
    "    \n",
    "    R += reward\n",
    "    \n",
    "    if terminated:\n",
    "        print('Term')\n",
    "        break\n",
    "    elif truncated:\n",
    "        print('Outbound')\n",
    "        break\n",
    "    else:\n",
    "        continue\n",
    "# video_recorder.close()\n",
    "# video_recorder.enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95bf5a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "newEnv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8dbc5cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "780.1297149379589"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39204a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
