{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05d518ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This implementation is based on the guidance from the SpinningUp article:\n",
    "https://spinningup.openai.com/en/latest/algorithms/td3.html\n",
    "\"\"\"\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "## ----------------- Helpers ---------------- ## \n",
    "\n",
    "def flatten(nestedTuple: tuple):\n",
    "    \"\"\"\n",
    "    flatten input dimensions for NNs\n",
    "    \"\"\"\n",
    "    merged = []\n",
    "    for item in nestedTuple:\n",
    "        if isinstance(item, tuple) or isinstance(item, list):\n",
    "            for i in item:\n",
    "                merged.append(i)\n",
    "        else:\n",
    "            merged.append(item)  \n",
    "    return merged   \n",
    "\n",
    "## This function aims to help updating target actor/critic parameters\n",
    "def targetUpdater(normalModel, targetModel, lRate = 0.3):\n",
    "    for normalParam, targetParam in zip(normalModel.parameters(), targetModel.parameters()):\n",
    "        targetParam.data.copy_(targetParam.data * (1.0 - lRate) + normalParam.data * lRate)\n",
    "## This function aims to initilize target actor/critic parameters with normal Actor/Critc \n",
    "def initializer(normalModel, targetModel):\n",
    "    for normalParam, targetParam in zip(normalModel.parameters(), targetModel.parameters()):\n",
    "        targetParam.data.copy_(normalParam.data)\n",
    "    \n",
    "## ------------------ Actor ----------------- ## \n",
    "\n",
    "class Actor(nn.Module):\n",
    "    \"\"\"\n",
    "    hidden layer can be further defined using another tuple e.g. (30, (128,64), 8) \n",
    "    or simply define in one tuple (30, 128, 64, 8)\n",
    "    \"\"\"\n",
    "    def __init__(self, structure, use_dropout = False):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        layers = []\n",
    "        ## Activation function:\n",
    "        self.activation  = nn.ReLU()\n",
    "        \n",
    "        # Automatic population of FC network\n",
    "        dim = flatten(structure)\n",
    "        dim_shifted = dim[1:]\n",
    "        \n",
    "        for i in range(len(dim)-1):\n",
    "            layers.append(nn.Linear(dim[i], dim_shifted[i]))\n",
    "            \n",
    "            ## Just in case for mitigating overfitting ...\n",
    "            if use_dropout and i != len(dim)-2:\n",
    "                layers.append(nn.Dropout(p = 0.2))\n",
    "            \n",
    "            if i != len(dim)-2:\n",
    "                layers.append(self.activation)\n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, states):\n",
    "        output = self.model(states)\n",
    "        ## This is to scale back the actions to (-1, 1) for Ant environment !Need to change for other environmen\n",
    "        output = torch.tanh(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "## -------------------Critic ---------------- ## \n",
    "class Critic(nn.Module):\n",
    "    \"\"\"\n",
    "    Critic network input dimension must equal the states_dim + actions_dim\n",
    "    \"\"\"\n",
    "    def __init__(self, structure, use_dropout = False):\n",
    "        super().__init__()\n",
    "        \n",
    "        layers = []\n",
    "        ## Activation function:\n",
    "        self.activation  = nn.ReLU()\n",
    "        \n",
    "        # Automatic population of FC network\n",
    "        dim = flatten(structure)\n",
    "        dim_shifted = dim[1:]\n",
    "        \n",
    "        for i in range(len(dim)-1):\n",
    "            layers.append(nn.Linear(dim[i], dim_shifted[i]))\n",
    "            \n",
    "            ## Just in case for mitigating overfitting ...\n",
    "            if use_dropout and i != len(dim)-2:\n",
    "                layers.append(nn.Dropout(p = 0.2))\n",
    "                \n",
    "            if i != len(dim)-2:\n",
    "                layers.append(self.activation)\n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, states, actions):\n",
    "        \n",
    "        ## concatenate states and actions, order shouldn't really matter\n",
    "        inputs = torch.cat([states, actions], 1)\n",
    "        output = self.model(inputs)\n",
    "        return output\n",
    "\n",
    "\n",
    "## -------------------Replay ---------------- ## \n",
    "class ReplayMemory():\n",
    "    \n",
    "    def __init__(self, size=500):\n",
    "        self.size = size\n",
    "        self.memory = []\n",
    "        \n",
    "    def addMemory(self, transition):\n",
    "        \"\"\"\n",
    "        Transition composition:\n",
    "        State, Action, Reward, `State\n",
    "        \"\"\"\n",
    "        if self.isFull():\n",
    "            ## If memory is full, remove the first stored elements\n",
    "            self.memory.pop(0)\n",
    "            \n",
    "        self.memory.append(transition)\n",
    "                \n",
    "    def sample(self, batchSize):\n",
    "        ## This is a very slow implementation - should be optimized if possible\n",
    "        batch = random.sample(self.memory, batchSize)\n",
    "        state, action, reward, stateNext, terminated = [], [], [], [], []\n",
    "        for transition in batch:\n",
    "            state.append(transition[0])\n",
    "            action.append(transition[1])\n",
    "            reward.append(transition[2])\n",
    "            stateNext.append(transition[3])\n",
    "            terminated.append(transition[4])\n",
    "        \n",
    "        return state, action, reward, stateNext, terminated\n",
    "    \n",
    "    def isFull(self):\n",
    "        return len(self.memory)==self.size\n",
    "    \n",
    "    def getSize(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "\n",
    "## ------------------- Target policy smoothing ---------------- ## \n",
    "class policySmooth:\n",
    "    def __init__(self,  actionSpace, std = 0.2, clip = 0.3,):\n",
    "        \n",
    "        self.std = std\n",
    "        self.clip = clip\n",
    "        self.size = actionSpace.shape[0]\n",
    "        self.high = actionSpace.high\n",
    "        self.low = actionSpace.low\n",
    "        \n",
    "    def getAction(self, actionIn, noiseClip = True):\n",
    "        noise = np.random.normal(0, self.std, self.size)\n",
    "        \n",
    "        ## For action no clipping, for target action apply clip\n",
    "        if noiseClip:\n",
    "            noise = np.clip(noise, -self.clip, self.clip)\n",
    "        action = actionIn + noise\n",
    "        \n",
    "        return np.clip(action, self.low, self.high)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1dddd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "class TD3Agent:\n",
    "    \n",
    "    def __init__(self, actionSpace, actorStructure:tuple, criticStructure:tuple, use_dropout = False, actorLRate = 0.0003, criticLRate = 0.0003, criticLoss = 'HL', gamma = 0.9, targetUpdaterLRate = 0.3, replayMemorySize = 500, batchSize = 128, policyDelay = 2, gpu = True):\n",
    "        \n",
    "        self.actor = Actor(structure=actorStructure, use_dropout = use_dropout)\n",
    "        self.critic1 = Critic(structure=criticStructure, use_dropout = use_dropout)\n",
    "        self.critic2 = Critic(structure=criticStructure, use_dropout = use_dropout)\n",
    "        \n",
    "        self.targetActor = Actor(structure=actorStructure, use_dropout = use_dropout)\n",
    "        self.targetCritic1 = Critic(structure=criticStructure, use_dropout = use_dropout)\n",
    "        self.targetCritic2 = Critic(structure=criticStructure, use_dropout = use_dropout)\n",
    "        \n",
    "        self.batchSize = batchSize\n",
    "        self.targetUpdaterLRate = targetUpdaterLRate\n",
    "        self.gamma = gamma\n",
    "        self.gpu = gpu\n",
    "        self.policyDelay = policyDelay\n",
    "        if self.gpu:\n",
    "            self.cuda()\n",
    "        \n",
    "        ## initialise target models \n",
    "        initializer(self.actor, self.targetActor)\n",
    "        initializer(self.critic1, self.targetCritic1)\n",
    "        initializer(self.critic2, self.targetCritic2)\n",
    "        \n",
    "        ## initialise replay memory and random process\n",
    "        self.pSmooth = policySmooth(actionSpace)\n",
    "        self.rMemory = ReplayMemory(replayMemorySize)\n",
    " \n",
    "        \n",
    "        ## initialise optimizer\n",
    "        self.actorOptim = optim.Adam(self.actor.parameters(), lr=actorLRate)\n",
    "        self.criticOptim1 = optim.Adam(self.critic1.parameters(), lr=criticLRate)\n",
    "        self.criticOptim2 = optim.Adam(self.critic2.parameters(), lr=criticLRate)\n",
    "        \n",
    "        ## initialise Loss for critic, either Huber (default) or MSE (otherwise)\n",
    "        if criticLoss == 'HL':\n",
    "            self.criticCriteria1 = nn.HuberLoss()\n",
    "            self.criticCriteria2 = nn.HuberLoss()\n",
    "        \n",
    "        else:\n",
    "            self.criticCriteria1 = nn.MSELoss()\n",
    "            self.criticCriteria2 = nn.MSELoss()\n",
    "    def updatePolicy(self, num):\n",
    "        ## Assuming sufficient replay memory has been acquired\n",
    "        \n",
    "        ## 1. Sample (S, A, R, S`) in replay memory\n",
    "\n",
    "        state, action, reward, stateNext, terminated = self.rMemory.sample(self.batchSize)\n",
    "\n",
    "        if self.gpu:\n",
    "            state = torch.cuda.FloatTensor(state)\n",
    "            action = torch.cuda.FloatTensor(action)\n",
    "            reward = torch.cuda.FloatTensor(reward)\n",
    "            stateNext = torch.cuda.FloatTensor(stateNext)\n",
    "            terminated = torch.cuda.FloatTensor(terminated)\n",
    "\n",
    "        else:\n",
    "            state = torch.FloatTensor(state)\n",
    "            action = torch.FloatTensor(action)\n",
    "            reward = torch.FloatTensor(reward)\n",
    "            stateNext = torch.FloatTensor(stateNext)\n",
    "            terminated = torch.FloatTensor(terminated)\n",
    "\n",
    "        ## 2. Gradient of actor and critic  \n",
    "\n",
    "        targetAction = self.pSmooth.getAction(self.targetActor(stateNext).detach().cpu().numpy(), noiseClip=True)\n",
    "        if self.gpu:\n",
    "            targetAction = torch.cuda.FloatTensor(targetAction)\n",
    "        else:\n",
    "            targetAction = torch.FloatTensor(targetAction)\n",
    "        Q1 = self.targetCritic1(stateNext.detach(), targetAction.detach())\n",
    "        Q2 = self.targetCritic2(stateNext.detach(), targetAction.detach())\n",
    "\n",
    "        ## SMALLER Q Proceed (this verion consider actions individually)\n",
    "        if Q1.mean() > Q2.mean():\n",
    "            Q = Q2\n",
    "        else:\n",
    "            Q = Q1\n",
    "\n",
    "        y = self.gamma * (1 - terminated) * Q + reward\n",
    "        y.requires_grad_()\n",
    "\n",
    "\n",
    "        yBar1 = self.critic1(state, action)\n",
    "        yBar2 = self.critic2(state, action)\n",
    "\n",
    "        criticLoss1 = self.criticCriteria1(yBar1, y)\n",
    "        criticLoss2 = self.criticCriteria2(yBar2, y)\n",
    "\n",
    "        ## backward losses\n",
    "        self.criticOptim1.zero_grad()\n",
    "        criticLoss1.backward(retain_graph = True)\n",
    "        self.criticOptim1.step()\n",
    "\n",
    "        self.criticOptim2.zero_grad()\n",
    "        criticLoss2.backward()\n",
    "        self.criticOptim2.step()\n",
    "\n",
    "        ## update actor when delay condition is met\n",
    "        if num % self.policyDelay == 0:\n",
    "            actorLoss = -self.critic1(state, self.actor(state)).mean()\n",
    "            self.actorOptim.zero_grad()\n",
    "            actorLoss.backward()\n",
    "            self.actorOptim.step()\n",
    "        ## 3. Update target actor / critic\n",
    "            targetUpdater(self.critic1, self.targetCritic1, self.targetUpdaterLRate)\n",
    "            targetUpdater(self.critic2, self.targetCritic2, self.targetUpdaterLRate)\n",
    "            targetUpdater(self.actor, self.targetActor, self.targetUpdaterLRate)\n",
    "\n",
    "\n",
    "    \n",
    "    ## Add option to discard noise in eval mode\n",
    "    def getAction(self, states, eval = False):\n",
    "        if self.gpu:\n",
    "            states = torch.cuda.FloatTensor(states)\n",
    "        else:\n",
    "            states = torch.FloatTensor(states)\n",
    "        \n",
    "        action = self.actor(states).detach().cpu().numpy()\n",
    "        \n",
    "        # Action selection without noise clip\n",
    "        if not eval:\n",
    "            action = self.pSmooth.getAction(action, noiseClip=False)\n",
    "            \n",
    "        return action\n",
    "    \n",
    "    def cuda(self):\n",
    "        ## Move all models to GPU\n",
    "        if torch.cuda.is_available():\n",
    "            self.actor.cuda()\n",
    "            self.critic1.cuda()\n",
    "            self.critic2.cuda()\n",
    "            self.targetActor.cuda()\n",
    "            self.targetCritic1.cuda()\n",
    "            self.targetCritic2.cuda()\n",
    "        else:\n",
    "            raise ValueError(\"No Cuda Available\")\n",
    "            \n",
    "    def cpu(self):\n",
    "        ## Move all models back to CPU\n",
    "        self.actor.cpu()\n",
    "        self.critic1.cpu()\n",
    "        self.critic2.cpu()\n",
    "        self.targetActor.cpu()\n",
    "        self.targetCritic1.cpu()\n",
    "        self.targetCritic2.cpu()\n",
    "        \n",
    "    def evalMode(self):\n",
    "        ## Evaluation mode for Agent showcase \n",
    "        self.actor.eval()\n",
    "        self.critic1.eval()\n",
    "        self.critic2.eval()\n",
    "        self.targetActor.eval()\n",
    "        self.targetCritic1.eval()  \n",
    "        self.targetCritic2.eval() \n",
    "        \n",
    "    def trainMode(self):\n",
    "        ## Training mode for updating parameters\n",
    "        self.actor.train()\n",
    "        self.critic1.train()\n",
    "        self.critic2.train()\n",
    "        self.targetActor.train()\n",
    "        self.targetCritic1.train() \n",
    "        self.targetCritic2.train() \n",
    "        \n",
    "    def saveModel(self, path):\n",
    "        torch.save(self.actor.state_dict(),f'{path}/actor.pkl')\n",
    "        torch.save(self.targetActor.state_dict(),f'{path}/targetActor.pkl')\n",
    "        \n",
    "        torch.save(self.critic1.state_dict(),f'{path}/critic1.pkl')\n",
    "        torch.save(self.critic2.state_dict(),f'{path}/critic2.pkl')\n",
    "        \n",
    "        torch.save(self.targetCritic1.state_dict(),f'{path}/targetCritic1.pkl')\n",
    "        torch.save(self.targetCritic2.state_dict(),f'{path}/targetCritic2.pkl')    \n",
    "        \n",
    "    def loadModel(self, path):\n",
    "        self.actor.load_state_dict(torch.load(f'{path}/actor.pkl'))\n",
    "        self.targetActor.load_state_dict(torch.load(f'{path}/targetActor.pkl'))\n",
    "        \n",
    "        self.critic1.load_state_dict(torch.load(f'{path}/critic1.pkl'))\n",
    "        self.critic2.load_state_dict(torch.load(f'{path}/critic2.pkl'))\n",
    "        \n",
    "        self.targetCritic1.load_state_dict(torch.load(f'{path}/targetCritic1.pkl'))\n",
    "        self.targetCritic2.load_state_dict(torch.load(f'{path}/targetCritic2.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdefa0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(agent, env, epochs, replayMemorySize, updateStart, printEvery = 100, savePath=None):\n",
    "\n",
    "    # ## Training Loop\n",
    "    try:\n",
    "        modelSaveCounter = 0\n",
    "        maxR = -np.inf\n",
    "        \n",
    "        for e in range(epochs):\n",
    "            state = env.reset()    \n",
    "            episodeR = 0\n",
    "            t = 0\n",
    "            # Training loop for each episode\n",
    "            while True:\n",
    "                \n",
    "                # Fill in the replay memory\n",
    "                action = agent.getAction(state)\n",
    "                stateNext, reward, terminated, truncated, info = env.step(action)\n",
    "                agent.rMemory.addMemory((state, action, np.array([reward]), stateNext, np.array([terminated])))\n",
    "\n",
    "                ## Update policy when memory is ready\n",
    "                if agent.rMemory.getSize() > updateStart: \n",
    "                    agent.updatePolicy(t)\n",
    "                    t+=1\n",
    "\n",
    "                ## renew state and action\n",
    "                state = stateNext\n",
    "                episodeR += reward\n",
    "       \n",
    "                if terminated or truncated:\n",
    "                    break\n",
    "                \n",
    "            rewardTracking.append(episodeR)\n",
    "            rewardAvg.append(np.mean(rewardTracking[-10:]))\n",
    "            \n",
    "            if e > 5 and rewardTracking[-1] > maxR:\n",
    "                maxR = rewardTracking[-1]\n",
    "            \n",
    "                ## Only save model if reward increased\n",
    "                if savePath!=None:\n",
    "                    agent.saveModel(savePath)\n",
    "                    modelSaveCounter += 1\n",
    "                \n",
    "            if (e+1)%printEvery == 0:\n",
    "                print(f\"Episode {e+1}: reward: {episodeR}, Avg: {rewardAvg[-1]}, model improved {modelSaveCounter} times in {printEvery} episodes training.\")\n",
    "                modelSaveCounter = 0\n",
    "                \n",
    "    ## In case looping for too long\n",
    "    except KeyboardInterrupt:\n",
    "        return rewardTracking, rewardAvg \n",
    "    \n",
    "    return rewardTracking, rewardAvg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2d815e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 10: reward: -467.1536028030095, Avg: -265.1296802109524, model improved 3 times in 10 episodes training.\n",
      "Episode 20: reward: -11.899758825918855, Avg: -228.22582935981978, model improved 0 times in 10 episodes training.\n",
      "Episode 30: reward: 657.6354591662836, Avg: 427.17738218723025, model improved 0 times in 10 episodes training.\n",
      "Episode 40: reward: 715.6723388605615, Avg: 706.8440124924736, model improved 1 times in 10 episodes training.\n",
      "Episode 50: reward: 876.9561690657107, Avg: 806.8318837455339, model improved 3 times in 10 episodes training.\n",
      "Episode 60: reward: 27.262726497728107, Avg: 599.8368769863971, model improved 3 times in 10 episodes training.\n",
      "Episode 70: reward: 381.4449408638193, Avg: 350.38088665090737, model improved 0 times in 10 episodes training.\n",
      "Episode 80: reward: 78.19873909272731, Avg: 264.6689607053269, model improved 1 times in 10 episodes training.\n",
      "Episode 90: reward: 217.12691532802185, Avg: 546.8462809823006, model improved 0 times in 10 episodes training.\n",
      "Episode 100: reward: 320.28600694364604, Avg: 405.4802503076581, model improved 1 times in 10 episodes training.\n",
      "Episode 110: reward: 302.91375586337796, Avg: 516.7592598064668, model improved 1 times in 10 episodes training.\n",
      "Episode 120: reward: 136.09785839476172, Avg: 388.8289360687915, model improved 0 times in 10 episodes training.\n",
      "Episode 130: reward: 33.07770269925298, Avg: 163.92267469047738, model improved 0 times in 10 episodes training.\n",
      "Episode 140: reward: 188.3997845186674, Avg: 237.47101651870716, model improved 0 times in 10 episodes training.\n",
      "Episode 150: reward: 890.1486154136896, Avg: 343.9746362057707, model improved 0 times in 10 episodes training.\n",
      "Episode 160: reward: 690.7050664829734, Avg: 418.91268503010207, model improved 0 times in 10 episodes training.\n",
      "Episode 170: reward: 263.570035876894, Avg: 231.7682002151811, model improved 0 times in 10 episodes training.\n",
      "Episode 180: reward: 649.9872198214047, Avg: 302.08928203774104, model improved 0 times in 10 episodes training.\n",
      "Episode 190: reward: 30.454248378208984, Avg: 374.9674168407021, model improved 0 times in 10 episodes training.\n",
      "Episode 200: reward: 56.895526684747644, Avg: 142.21012628328896, model improved 0 times in 10 episodes training.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script is used as main for learning\n",
    "\"\"\"\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "## reset environment, render is not used in training\n",
    "env = gym.make('Ant-v4', new_step_api = True)\n",
    "env.action_space.seed(42)\n",
    "state = env.reset()\n",
    "\n",
    "## Observation and action space size\n",
    "observationNum = env.observation_space.shape[0]\n",
    "actionNum = env.action_space.shape[0]\n",
    "totalNum = observationNum + actionNum\n",
    "\n",
    "## Training Parameters\n",
    "epochs = 200\n",
    "batchSize = 128\n",
    "gpu = False\n",
    "rewardTracking = []\n",
    "rewardAvg = []\n",
    "replayMemorySize = 10000\n",
    "printE = 10\n",
    "path = '/home/linghao/Desktop/'\n",
    "updateStart = 5000\n",
    "## Initialise TD3 agent\n",
    "\n",
    "## Some implementation suggest a single output from critic - can try\n",
    "agent = TD3Agent(env.action_space,\n",
    "                (observationNum, 256, 128, actionNum), \n",
    "                (totalNum, 256, 128, actionNum), \n",
    "                actorLRate = 0.0001, criticLRate = 0.0001, criticLoss = 'HL', gamma = 0.95, targetUpdaterLRate = 0.05,\n",
    "                replayMemorySize = replayMemorySize, gpu=gpu, batchSize=batchSize)\n",
    "agent.trainMode()\n",
    "trackR, avgR = train(agent, env, epochs=epochs, replayMemorySize = replayMemorySize, updateStart = updateStart, printEvery=printE, savePath=path)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b619d3ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fdf2cb7c3d0>]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(avgR)\n",
    "# plt.plot(trackR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a26dcc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outbound\n"
     ]
    }
   ],
   "source": [
    "# import gym\n",
    "# from gym.wrappers.monitoring.video_recorder import VideoRecorder\n",
    "import gym\n",
    "# from gym.wrappers.monitoring.video_recorder import VideoRecorder\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "## Observation and action space size\n",
    "observationNum = 27\n",
    "actionNum = 8\n",
    "totalNum = observationNum + actionNum\n",
    "\n",
    "## Training Parameters\n",
    "epochs = 200\n",
    "batchSize = 128\n",
    "gpu = False\n",
    "rewardTracking = []\n",
    "rewardAvg = []\n",
    "replayMemorySize = 10000\n",
    "printE = 10\n",
    "path = '/home/linghao/Desktop/'\n",
    "updateStart = 5000\n",
    "## Initialise TD3 agent\n",
    "\n",
    "newEnv =  gym.make('Ant-v4', render_mode = 'human', new_step_api = True)\n",
    "\n",
    "agentEval = TD3Agent(newEnv.action_space,\n",
    "                (observationNum, 256, 128, actionNum), \n",
    "                (totalNum, 256, 128, actionNum), \n",
    "                actorLRate = 0.0001, criticLRate = 0.0001, criticLoss = 'HL', gamma = 0.95, targetUpdaterLRate = 0.05,\n",
    "                replayMemorySize = replayMemorySize, gpu=gpu, batchSize=batchSize)\n",
    "agentEval.loadModel('/home/linghao/Desktop/TD3_V2/')\n",
    "agentEval.evalMode()\n",
    "\n",
    "\n",
    "observation = newEnv.reset()\n",
    "\n",
    " \n",
    "# video_recorder = VideoRecorder(newEnv, '/home/linghao/Desktop/Ant.mp4', enabled=True)\n",
    "\n",
    "R = 0\n",
    "\n",
    "for _ in range(1000):\n",
    "#     video_recorder.capture_frame()\n",
    "    observation, reward, terminated, truncated, info = newEnv.step(agentEval.getAction(observation, eval = True))\n",
    "    \n",
    "    R += reward\n",
    "    \n",
    "    if terminated:\n",
    "        print('Term')\n",
    "        break\n",
    "    elif truncated:\n",
    "        print('Outbound')\n",
    "        break\n",
    "    else:\n",
    "        continue\n",
    "# video_recorder.close()\n",
    "# video_recorder.enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0468e1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "newEnv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adbbea44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1768.322015946114"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bee3b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
